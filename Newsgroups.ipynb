{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#select the categories with which I'm familiar (so that I could actually evaluate the performance of the algorithms)\n",
    "\n",
    "categs =['alt.atheism',\n",
    "         'rec.autos',\n",
    "         'sci.electronics',\n",
    "         'sci.med',\n",
    "         'sci.space',\n",
    "         'soc.religion.christian',\n",
    "         'talk.politics.guns',\n",
    "         'talk.politics.mideast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove headers, footers, quotes to make it fair\n",
    "\n",
    "news_train = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'), categories = categs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating tf idf matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "news_train_tfidf = vectorizer.fit_transform(news_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4561, 46431)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the vocabulary\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=chosenlist\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 10\n",
    "ntopics=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "news_train_lsa = lsa.fit_transform(news_train_tfidf)\n",
    "\n",
    "components_lsa = word_topic(news_train_tfidf, news_train_lsa, vocabulary)\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "topwords['LSA']=top_words(components_lsa, n_top_words)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_components=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=1, \n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "news_train_lda = lda.fit_transform(news_train_tfidf) \n",
    "\n",
    "components_lda = word_topic(news_train_tfidf, news_train_lda, vocabulary)\n",
    "\n",
    "topwords['LDA']=top_words(components_lda, n_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "news_train_nmf = nmf.fit_transform(news_train_tfidf) \n",
    "\n",
    "components_nmf = word_topic(news_train_tfidf, news_train_nmf, vocabulary)\n",
    "\n",
    "topwords['NNMF']=top_words(components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identified Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "            LSA          LDA         NNMF\n",
      "0  people 51.49    like 2.21     don 2.48\n",
      "0     don 48.21     don 2.16  people 2.45\n",
      "0     just 47.6  people 2.13    just 2.41\n",
      "0    like 45.72    just 1.99    think 2.1\n",
      "0    know 43.82    know 1.88    know 2.09\n",
      "0   think 43.29    good 1.79    like 1.96\n",
      "0     god 38.93   think 1.76    does 1.34\n",
      "0    does 36.49    does 1.73    time 1.31\n",
      "0    time 33.26     car 1.72      say 1.3\n",
      "0     good 32.4    time 1.44    good 1.28\n",
      "Topic 1:\n",
      "               LSA          LDA             NNMF\n",
      "1         edu 13.1    like 2.43         geb 2.92\n",
      "1       banks 11.0    just 2.23         pitt 2.9\n",
      "1        geb 10.86  people 2.08          dsl 2.9\n",
      "1        pitt 10.8     don 2.08     chastity 2.9\n",
      "1     gordon 10.78    know 1.96        n3jxp 2.9\n",
      "1   shameful 10.67   think 1.79        cadre 2.9\n",
      "1  surrender 10.55    good 1.62    shameful 2.89\n",
      "1   chastity 10.51    right 1.6   intellect 2.87\n",
      "1      n3jxp 10.51     edu 1.58  skepticism 2.87\n",
      "1        dsl 10.51     car 1.53       banks 2.87\n",
      "Topic 2:\n",
      "               LSA          LDA             NNMF\n",
      "2        god 36.36    just 3.25         god 7.04\n",
      "2      jesus 13.83    know 2.96        jesus 2.6\n",
      "2       bible 9.69     don 2.89     believe 1.77\n",
      "2       faith 9.03    like 2.64       bible 1.71\n",
      "2     believe 7.82   think 2.32       faith 1.61\n",
      "2       church 7.3    does 2.19      people 1.54\n",
      "2  christians 7.29  people 2.15        does 1.37\n",
      "2      christ 7.22    good 1.96      christ 1.34\n",
      "2   christian 6.21      car 1.9         say 1.23\n",
      "2       truth 5.83     god 1.87  christians 1.21\n",
      "Topic 3:\n",
      "              LSA          LDA           NNMF\n",
      "3     israel 15.8    just 2.76    israel 3.91\n",
      "3      jews 10.87     don 2.49   israeli 2.12\n",
      "3   israeli 10.11    like 2.32      jews 1.68\n",
      "3   armenian 7.81    know 2.27      arab 1.37\n",
      "3    turkish 6.89  people 2.13     arabs 0.94\n",
      "3  armenians 6.83    does 2.12  lebanese 0.86\n",
      "3     people 6.65     god 1.92    lebanon 0.8\n",
      "3       arab 6.54     com 1.85     peace 0.77\n",
      "3      jewish 5.6   think 1.78    jewish 0.73\n",
      "3        war 5.46     edu 1.76      adam 0.73\n",
      "Topic 4:\n",
      "              LSA           LDA             NNMF\n",
      "4     space 11.73  people 47.53    armenian 2.87\n",
      "4    armenian 9.3     god 45.29   armenians 2.27\n",
      "4  armenians 7.84     don 43.56     turkish 2.05\n",
      "4    turkish 7.56     just 42.3      people 1.35\n",
      "4        god 4.96    like 39.67    genocide 1.17\n",
      "4       nasa 4.92   think 39.25      armenia 1.1\n",
      "4     turkey 4.12    know 38.46       turks 1.04\n",
      "4    armenia 4.03    does 33.16      turkey 1.02\n",
      "4   genocide 3.92    time 28.51  government 0.87\n",
      "4       turks 3.9    good 28.42      soviet 0.84\n",
      "Topic 5:\n",
      "            LSA         LDA          NNMF\n",
      "5   space 18.97   just 2.96    space 4.01\n",
      "5  israel 11.16   like 2.94     nasa 1.76\n",
      "5     nasa 8.72   know 2.66  shuttle 0.99\n",
      "5  israeli 6.38    don 2.57   launch 0.96\n",
      "5    orbit 5.01   does 2.17  program 0.83\n",
      "5   launch 4.62  people 2.1      data 0.8\n",
      "5  shuttle 4.61    god 2.06    orbit 0.79\n",
      "5  program 4.57  think 2.03     moon 0.75\n",
      "5     data 4.54   time 1.82    lunar 0.72\n",
      "5    earth 4.37    car 1.82     like 0.71\n",
      "Topic 6:\n",
      "           LSA             LDA         NNMF\n",
      "6    car 21.44     space 10.94     car 4.48\n",
      "6  thanks 8.57     people 9.52    cars 1.16\n",
      "6    cars 7.04   armenian 8.18    like 1.01\n",
      "6     god 6.11       like 7.86    good 0.92\n",
      "6  israel 5.72        don 6.94  dealer 0.84\n",
      "6     new 5.31       just 6.91     new 0.84\n",
      "6  engine 5.21       know 6.72  engine 0.83\n",
      "6  dealer 4.57  armenians 6.67  thanks 0.75\n",
      "6    jews 4.05       time 6.09    just 0.74\n",
      "6   price 3.95    turkish 6.04   price 0.65\n",
      "Topic 7:\n",
      "             LSA          LDA           NNMF\n",
      "7      gun 12.64     don 2.31       gun 3.54\n",
      "7      guns 7.31    like 2.25       guns 2.1\n",
      "7       car 7.01    know 2.25     people 1.5\n",
      "7        god 6.4    just 2.07       law 1.26\n",
      "7       law 5.92   think 2.02     crime 1.12\n",
      "7     crime 4.04    does 1.83       don 1.08\n",
      "7    police 3.84   people 1.8   weapons 1.04\n",
      "7    weapons 3.8  thanks 1.78   control 0.95\n",
      "7  firearms 3.76     edu 1.77  firearms 0.94\n",
      "7      laws 3.46    time 1.69      right 0.9\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'rec.autos',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(news_train.target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
