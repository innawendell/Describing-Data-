{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = pd.read_csv('/Users/admin/Documents/contextAdvertising1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799999, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 799999 entries, 0 to 799998\n",
      "Data columns (total 3 columns):\n",
      "atitle     799999 non-null object\n",
      "atext      799983 non-null object\n",
      "adomain    799999 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atitle</th>\n",
       "      <th>atext</th>\n",
       "      <th>adomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Клуб активного отдыха «0.67»</td>\n",
       "      <td>Детский пейнтбол. Спортивный пейнтбол. Тактиче...</td>\n",
       "      <td>0-67.relax.by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Антигравитационный чехол IPhone 5</td>\n",
       "      <td>Успейте купить антигравитационный чехол для IP...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Антигравитационный чехол купить!</td>\n",
       "      <td>Антигравитационный чехол для телефона купить з...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Беспроцентный заем от Moneyveo</td>\n",
       "      <td>Без справок! Получите до 3 000 грн. на карту п...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Беспроцентный заем сотруднику</td>\n",
       "      <td>Акция! Получите Кредит Онлайн под 0%. Без Спра...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              atitle  \\\n",
       "0       Клуб активного отдыха «0.67»   \n",
       "1  Антигравитационный чехол IPhone 5   \n",
       "2   Антигравитационный чехол купить!   \n",
       "3     Беспроцентный заем от Moneyveo   \n",
       "4      Беспроцентный заем сотруднику   \n",
       "\n",
       "                                               atext               adomain  \n",
       "0  Детский пейнтбол. Спортивный пейнтбол. Тактиче...         0-67.relax.by  \n",
       "1  Успейте купить антигравитационный чехол для IP...      0-antigravity.ru  \n",
       "2  Антигравитационный чехол для телефона купить з...      0-antigravity.ru  \n",
       "3  Без справок! Получите до 3 000 грн. на карту п...  0-credit.moneyveo.ua  \n",
       "4  Акция! Получите Кредит Онлайн под 0%. Без Спра...  0-credit.moneyveo.ua  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include all the punctuation signs\\n\",\n",
    "def punctuation_remover(row):\n",
    "    punctuation = '!\"#$&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~«»'\n",
    "    \n",
    "    punctuationNoPeriod = \"[\" + re.sub(\"\\.\",\"\", punctuation) + \"]\"\n",
    "    row = re.sub(punctuationNoPeriod, \" \", str(row))\n",
    "    #to remove double white spaces and create space after %,\n",
    "    row = row.replace('  ', ' ')\n",
    "    row = row.replace('%', '% ')\n",
    "    return row.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from the ads text\n",
    "ads['atext'] = ads['atext'].apply(punctuation_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from the ads text\n",
    "ads['atitle'] = ads['atext'].apply(punctuation_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atitle     348184\n",
       "atext      348409\n",
       "adomain     19181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ads['atitle'] + ads['atext']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique =ads.drop_duplicates(subset = ['atext'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique =unique.drop_duplicates(subset = ['atitle'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique= unique.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atitle     320632\n",
       "atext      320632\n",
       "adomain      4818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320632, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atitle</th>\n",
       "      <th>atext</th>\n",
       "      <th>adomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Детский пейнтбол Спортивный пейнтбол Тактическ...</td>\n",
       "      <td>Детский пейнтбол Спортивный пейнтбол Тактическ...</td>\n",
       "      <td>0-67.relax.by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Успейте купить антигравитационный чехол для IP...</td>\n",
       "      <td>Успейте купить антигравитационный чехол для IP...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Антигравитационный чехол для телефона купить з...</td>\n",
       "      <td>Антигравитационный чехол для телефона купить з...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Без справок Получите до 3 000 грн на карту под...</td>\n",
       "      <td>Без справок Получите до 3 000 грн на карту под...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Акция Получите Кредит Онлайн под 0%  Без Справ...</td>\n",
       "      <td>Акция Получите Кредит Онлайн под 0%  Без Справ...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              atitle  \\\n",
       "0  Детский пейнтбол Спортивный пейнтбол Тактическ...   \n",
       "1  Успейте купить антигравитационный чехол для IP...   \n",
       "2  Антигравитационный чехол для телефона купить з...   \n",
       "3  Без справок Получите до 3 000 грн на карту под...   \n",
       "4  Акция Получите Кредит Онлайн под 0%  Без Справ...   \n",
       "\n",
       "                                               atext               adomain  \n",
       "0  Детский пейнтбол Спортивный пейнтбол Тактическ...         0-67.relax.by  \n",
       "1  Успейте купить антигравитационный чехол для IP...      0-antigravity.ru  \n",
       "2  Антигравитационный чехол для телефона купить з...      0-antigravity.ru  \n",
       "3  Без справок Получите до 3 000 грн на карту под...  0-credit.moneyveo.ua  \n",
       "4  Акция Получите Кредит Онлайн под 0%  Без Справ...  0-credit.moneyveo.ua  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,     10,     11,     12,\n",
       "                13,     14,\n",
       "            ...\n",
       "            772509, 772510, 772512, 772515, 772516, 772517, 772518, 772519,\n",
       "            772520, 772521],\n",
       "           dtype='int64', length=320632)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = unique.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_parser(series): \n",
    "    series_copy = series.copy()\n",
    "    list_of_strings = []\n",
    "    for row in series:\n",
    "        row= row.lower().split()      \n",
    "        list_of_strings.append(row)\n",
    "        series_copy=list_of_strings\n",
    "    return series_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Детский пейнтбол Спортивный пейнтбол Тактический пейнтбол Выездные игры\n",
      "Успейте купить антигравитационный чехол для IPhone Второй всего за 990 руб\n",
      "Антигравитационный чехол для телефона купить здесь Успейте купить за 1990р\n"
     ]
    }
   ],
   "source": [
    "for entry in unique['atitle'].iloc[:3]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ads = unique.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320632, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ads['atitle'] = text_parser(unique['atitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ads['atext'] = text_parser(unique['atext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atitle</th>\n",
       "      <th>atext</th>\n",
       "      <th>adomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[детский, пейнтбол, спортивный, пейнтбол, такт...</td>\n",
       "      <td>[детский, пейнтбол, спортивный, пейнтбол, такт...</td>\n",
       "      <td>0-67.relax.by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[успейте, купить, антигравитационный, чехол, д...</td>\n",
       "      <td>[успейте, купить, антигравитационный, чехол, д...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[антигравитационный, чехол, для, телефона, куп...</td>\n",
       "      <td>[антигравитационный, чехол, для, телефона, куп...</td>\n",
       "      <td>0-antigravity.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[без, справок, получите, до, 3, 000, грн, на, ...</td>\n",
       "      <td>[без, справок, получите, до, 3, 000, грн, на, ...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[акция, получите, кредит, онлайн, под, 0%, без...</td>\n",
       "      <td>[акция, получите, кредит, онлайн, под, 0%, без...</td>\n",
       "      <td>0-credit.moneyveo.ua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              atitle  \\\n",
       "0  [детский, пейнтбол, спортивный, пейнтбол, такт...   \n",
       "1  [успейте, купить, антигравитационный, чехол, д...   \n",
       "2  [антигравитационный, чехол, для, телефона, куп...   \n",
       "3  [без, справок, получите, до, 3, 000, грн, на, ...   \n",
       "4  [акция, получите, кредит, онлайн, под, 0%, без...   \n",
       "\n",
       "                                               atext               adomain  \n",
       "0  [детский, пейнтбол, спортивный, пейнтбол, такт...         0-67.relax.by  \n",
       "1  [успейте, купить, антигравитационный, чехол, д...      0-antigravity.ru  \n",
       "2  [антигравитационный, чехол, для, телефона, куп...      0-antigravity.ru  \n",
       "3  [без, справок, получите, до, 3, 000, грн, на, ...  0-credit.moneyveo.ua  \n",
       "4  [акция, получите, кредит, онлайн, под, 0%, без...  0-credit.moneyveo.ua  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ads['combined'] = split_ads['atext'] +split_ads['atitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = word2vec.Word2Vec(\n",
    "    split_ads['combined'],\n",
    "    workers=-1,     \n",
    "    min_count=5,   \n",
    "    window=30,      \n",
    "    sg=0,          \n",
    "    sample=1e-3 ,  \n",
    "    size=300,      \n",
    "    hs=1           \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44011\n"
     ]
    }
   ],
   "source": [
    "vocabulary = model_w2v.wv.vocab.keys()\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model_w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = split_ads['atext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224442"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96190"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44011"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab=Counter()\n",
    "\n",
    "for entry in X_train:\n",
    "    vocab.update(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {t[0]: i+1 for i,t in enumerate(vocab.most_common(MAX_NB_WORDS))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = [[word_index.get(t, 0) for t in ad_text]\n",
    "             for ad_text in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = [[word_index.get(t, 0) for t in ad_text]\n",
    "             for ad_text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in training_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in test_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = max([len(x) for x in training_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_sequence_generator(input_text):\n",
    "    ngram_inputs = []\n",
    "    for entry in input_text:\n",
    "        for i in range(1, len(entry)):\n",
    "            ngram_seq = entry[:i+1]\n",
    "            ngram_inputs.append(ngram_seq)\n",
    "            \n",
    "    return ngram_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_input_sequences_training = ngram_sequence_generator(training_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_input_sequences_test = ngram_sequence_generator(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[183, 44],\n",
       " [183, 44, 4],\n",
       " [183, 44, 4, 20],\n",
       " [183, 44, 4, 20, 1643],\n",
       " [183, 44, 4, 20, 1643, 15680],\n",
       " [183, 44, 4, 20, 1643, 15680, 6],\n",
       " [183, 44, 4, 20, 1643, 15680, 6, 21],\n",
       " [183, 44, 4, 20, 1643, 15680, 6, 21, 941],\n",
       " [171, 1],\n",
       " [171, 1, 30],\n",
       " [171, 1, 30, 45],\n",
       " [171, 1, 30, 45, 346],\n",
       " [171, 1, 30, 45, 346, 354],\n",
       " [171, 1, 30, 45, 346, 354, 5],\n",
       " [171, 1, 30, 45, 346, 354, 5, 1038],\n",
       " [171, 1, 30, 45, 346, 354, 5, 1038, 3589],\n",
       " [298, 2440],\n",
       " [298, 2440, 574],\n",
       " [298, 2440, 574, 14],\n",
       " [298, 2440, 574, 14, 4]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_input_sequences_training[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def generate_padded_sequence(input_sequences):\n",
    "    input_sequences = pad_sequences(input_sequences, maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                     padding=\"pre\", truncating=\"post\")\n",
    "    \n",
    "\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = to_categorical(label, num_classes=MAX_NB_WORDS+1)\n",
    "    return predictors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_tr, label_tr = generate_padded_sequence(ngram_input_sequences_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_test, label_test = generate_padded_sequence(ngram_input_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997772"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_maxtrix = len(vocabulary)+1\n",
    "\n",
    "embedding_matrix = np.zeros((length_maxtrix, 300))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "            continue\n",
    "    try:        \n",
    "        embedding_vector = word_vectors[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        if embedding_vector is not None:  \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44012, 300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = Sequential()\n",
    "model_gen.add(Embedding(MAX_NB_WORDS +1,\n",
    "                     WV_DIM,\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH-1,\n",
    "                     trainable=False))\n",
    "\n",
    "model_gen.add(GRU(200))\n",
    "model_gen.add(Dropout(0.2))\n",
    "model_gen.add(BatchNormalization())\n",
    "model_gen.add(Dense(MAX_NB_WORDS+1, activation = 'softmax'))\n",
    "\n",
    "model_gen.compile(loss='categorical_crossentropy', \n",
    "                   optimizer = 'adam', \n",
    "                   metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 9.1384 - acc: 0.0587 - val_loss: 7.7258 - val_acc: 0.0920\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 6.5110 - acc: 0.1282 - val_loss: 7.4694 - val_acc: 0.1450\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 42s 4ms/step - loss: 6.0257 - acc: 0.1674 - val_loss: 6.9321 - val_acc: 0.1620\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 5.6784 - acc: 0.1961 - val_loss: 7.0421 - val_acc: 0.1870\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 5.3889 - acc: 0.2094 - val_loss: 6.9218 - val_acc: 0.2060\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 5.1308 - acc: 0.2208 - val_loss: 7.0327 - val_acc: 0.2170\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 4.8888 - acc: 0.2337 - val_loss: 7.1489 - val_acc: 0.2290\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 4.6684 - acc: 0.2413 - val_loss: 7.0736 - val_acc: 0.2240\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 4.4206 - acc: 0.2567 - val_loss: 7.0788 - val_acc: 0.2400\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 4.1791 - acc: 0.2690 - val_loss: 7.0642 - val_acc: 0.2430\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 3.9337 - acc: 0.2825 - val_loss: 7.1051 - val_acc: 0.2460\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 3.6549 - acc: 0.3169 - val_loss: 7.1892 - val_acc: 0.2570\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 3.3817 - acc: 0.3469 - val_loss: 7.1432 - val_acc: 0.2480\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 3.1421 - acc: 0.3858 - val_loss: 7.2782 - val_acc: 0.2600\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 2.8609 - acc: 0.4253 - val_loss: 7.2717 - val_acc: 0.2660\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 2.6296 - acc: 0.4644 - val_loss: 7.2573 - val_acc: 0.2750\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 2.4148 - acc: 0.4988 - val_loss: 7.3845 - val_acc: 0.2550\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 2.2162 - acc: 0.5270 - val_loss: 7.3882 - val_acc: 0.2720\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 2.0290 - acc: 0.5644 - val_loss: 7.3324 - val_acc: 0.2790\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.8716 - acc: 0.5911 - val_loss: 7.3498 - val_acc: 0.2790\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 1.7325 - acc: 0.6179 - val_loss: 7.3813 - val_acc: 0.2730\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.5887 - acc: 0.6335 - val_loss: 7.2938 - val_acc: 0.2810\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.4983 - acc: 0.6538 - val_loss: 7.3743 - val_acc: 0.2830\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.3919 - acc: 0.6738 - val_loss: 7.5426 - val_acc: 0.2830\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 1.3047 - acc: 0.6928 - val_loss: 7.3686 - val_acc: 0.3030\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 1.2323 - acc: 0.7032 - val_loss: 7.5899 - val_acc: 0.2860\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.1511 - acc: 0.7137 - val_loss: 7.4483 - val_acc: 0.2970\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.0834 - acc: 0.7322 - val_loss: 7.6987 - val_acc: 0.2720\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 1.0375 - acc: 0.7376 - val_loss: 7.6410 - val_acc: 0.2830\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.9748 - acc: 0.7518 - val_loss: 7.6703 - val_acc: 0.2870\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.9324 - acc: 0.7623 - val_loss: 7.8260 - val_acc: 0.2760\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.8819 - acc: 0.7729 - val_loss: 7.6955 - val_acc: 0.2850\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.8344 - acc: 0.7813 - val_loss: 7.6940 - val_acc: 0.2950\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.7951 - acc: 0.7907 - val_loss: 7.8204 - val_acc: 0.2910\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.7662 - acc: 0.8010 - val_loss: 7.8181 - val_acc: 0.2900\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.7404 - acc: 0.8045 - val_loss: 7.8665 - val_acc: 0.2790\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.7025 - acc: 0.8158 - val_loss: 7.8951 - val_acc: 0.2870\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.6713 - acc: 0.8201 - val_loss: 7.9224 - val_acc: 0.2870\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.6351 - acc: 0.8273 - val_loss: 7.9681 - val_acc: 0.2800\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.6249 - acc: 0.8314 - val_loss: 7.8643 - val_acc: 0.2920\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.6159 - acc: 0.8324 - val_loss: 8.0086 - val_acc: 0.2890\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.5963 - acc: 0.8397 - val_loss: 7.9780 - val_acc: 0.2830\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.5608 - acc: 0.8476 - val_loss: 7.9987 - val_acc: 0.2910\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.5439 - acc: 0.8564 - val_loss: 8.0593 - val_acc: 0.2850\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.5408 - acc: 0.8545 - val_loss: 8.3444 - val_acc: 0.2840\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.5145 - acc: 0.8595 - val_loss: 8.1578 - val_acc: 0.2920\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.4936 - acc: 0.8642 - val_loss: 8.2469 - val_acc: 0.2860\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.4946 - acc: 0.8650 - val_loss: 8.4006 - val_acc: 0.2660\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.4785 - acc: 0.8681 - val_loss: 8.3921 - val_acc: 0.2890\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.4639 - acc: 0.8708 - val_loss: 8.3174 - val_acc: 0.2910\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.4488 - acc: 0.8776 - val_loss: 8.3379 - val_acc: 0.2860\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.4555 - acc: 0.8756 - val_loss: 8.3156 - val_acc: 0.2880\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.4399 - acc: 0.8780 - val_loss: 8.3873 - val_acc: 0.2890\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.4332 - acc: 0.8800 - val_loss: 8.4459 - val_acc: 0.2800\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.4254 - acc: 0.8840 - val_loss: 8.4288 - val_acc: 0.2890\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.4142 - acc: 0.8869 - val_loss: 8.6258 - val_acc: 0.2840\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.4102 - acc: 0.8868 - val_loss: 8.6639 - val_acc: 0.2820\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.4039 - acc: 0.8889 - val_loss: 8.7411 - val_acc: 0.2750\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3963 - acc: 0.8919 - val_loss: 8.4178 - val_acc: 0.2970\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.3941 - acc: 0.8910 - val_loss: 8.5690 - val_acc: 0.2710\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3798 - acc: 0.8951 - val_loss: 8.5909 - val_acc: 0.2900\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3933 - acc: 0.8911 - val_loss: 8.6827 - val_acc: 0.2830\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3817 - acc: 0.8931 - val_loss: 8.5605 - val_acc: 0.2890\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3747 - acc: 0.9000 - val_loss: 8.5023 - val_acc: 0.2890\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 0.3791 - acc: 0.8953 - val_loss: 8.6405 - val_acc: 0.2860\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3716 - acc: 0.8972 - val_loss: 8.6476 - val_acc: 0.2840\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.3662 - acc: 0.8981 - val_loss: 8.6389 - val_acc: 0.2930\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.3554 - acc: 0.9004 - val_loss: 8.6247 - val_acc: 0.2890\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 0.3615 - acc: 0.9011 - val_loss: 8.7684 - val_acc: 0.2770\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3480 - acc: 0.9029 - val_loss: 8.7357 - val_acc: 0.2850\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3523 - acc: 0.9009 - val_loss: 8.7435 - val_acc: 0.2930\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3518 - acc: 0.9031 - val_loss: 8.8293 - val_acc: 0.2780\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.3421 - acc: 0.9028 - val_loss: 8.6367 - val_acc: 0.2860\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.3420 - acc: 0.9064 - val_loss: 8.6918 - val_acc: 0.2790\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.3466 - acc: 0.9017 - val_loss: 8.7637 - val_acc: 0.2880\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.3465 - acc: 0.9036 - val_loss: 9.0027 - val_acc: 0.2740\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3400 - acc: 0.9052 - val_loss: 8.8486 - val_acc: 0.2830\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 0.3368 - acc: 0.9069 - val_loss: 8.8926 - val_acc: 0.2820\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.3351 - acc: 0.9079 - val_loss: 9.1001 - val_acc: 0.2820\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.3318 - acc: 0.9076 - val_loss: 8.8760 - val_acc: 0.2800\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.3278 - acc: 0.9093 - val_loss: 8.8505 - val_acc: 0.2820\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.3328 - acc: 0.9063 - val_loss: 8.7635 - val_acc: 0.2870\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.3279 - acc: 0.9099 - val_loss: 9.0712 - val_acc: 0.2710\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.3266 - acc: 0.9083 - val_loss: 8.9609 - val_acc: 0.2870\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3259 - acc: 0.9086 - val_loss: 8.9916 - val_acc: 0.2800\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3350 - acc: 0.9056 - val_loss: 8.8561 - val_acc: 0.2890\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.3226 - acc: 0.9076 - val_loss: 8.8287 - val_acc: 0.2860\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3248 - acc: 0.9103 - val_loss: 8.8993 - val_acc: 0.2830\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3226 - acc: 0.9074 - val_loss: 8.7756 - val_acc: 0.2900\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3186 - acc: 0.9103 - val_loss: 9.0366 - val_acc: 0.2720\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3131 - acc: 0.9090 - val_loss: 8.8549 - val_acc: 0.2900\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3102 - acc: 0.9103 - val_loss: 8.9823 - val_acc: 0.2840\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 0.3133 - acc: 0.9104 - val_loss: 8.8475 - val_acc: 0.2930\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 0.3198 - acc: 0.9099 - val_loss: 8.9969 - val_acc: 0.2730\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3131 - acc: 0.9128 - val_loss: 8.8882 - val_acc: 0.2840\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3119 - acc: 0.9129 - val_loss: 8.8398 - val_acc: 0.2770\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3104 - acc: 0.9109 - val_loss: 9.0068 - val_acc: 0.2810\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3127 - acc: 0.9126 - val_loss: 8.9146 - val_acc: 0.2890\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3048 - acc: 0.9156 - val_loss: 8.8725 - val_acc: 0.2880\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 0.3100 - acc: 0.9117 - val_loss: 8.9494 - val_acc: 0.2810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18826dbe0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gen.fit(predictors_tr[:10000], label_tr[:10000], \n",
    "               epochs = 100, \n",
    "               verbose=1,\n",
    "               batch_size=50,\n",
    "               shuffle=True,\n",
    "               validation_data = (predictors_test[:1000], label_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    output_sequence = ''\n",
    "    for _ in range(next_words):\n",
    "        seed_text = seed_text.lower()\n",
    "        seed_list = seed_text.split()\n",
    "        token_list = [word_index.get(word)for word in seed_list]\n",
    "        token_list= pad_sequences([token_list], maxlen=MAX_SEQUENCE_LENGTH-1, padding=\"pre\")\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    for word in seed_list:\n",
    "        output_sequence+=word+ ' '\n",
    "    return output_sequence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с нами покупка домена просто регистрация за 5 минут белее 100 зон от 220 вольт'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('с', 15, model_gen, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'двери купе в гардеробную от производителя в краснодаре низкие цены'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('двери', 10, model_gen, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen_larger = Sequential()\n",
    "model_gen_larger.add(Embedding(MAX_NB_WORDS +1,\n",
    "                     WV_DIM,\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH-1,\n",
    "                     trainable=False))\n",
    "\n",
    "model_gen_larger.add(GRU(100, return_sequences=True))\n",
    "model_gen_larger.add(Dropout(0.2))\n",
    "model_gen_larger.add(GRU(100))\n",
    "model_gen_larger.add(Dropout(0.2))\n",
    "model_gen_larger.add(BatchNormalization())\n",
    "model_gen_larger.add(Dense(MAX_NB_WORDS+1, activation = 'softmax'))\n",
    "\n",
    "model_gen_larger.compile(loss='categorical_crossentropy', \n",
    "                   optimizer = 'adam', \n",
    "                   metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "    30/200000 [..............................] - ETA: 3:28:17 - loss: 10.6923 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model_gen_larger.fit(predictors_tr[:200000], label_tr[:200000], \n",
    "               epochs = 30, \n",
    "               verbose=1,\n",
    "               batch_size=30,\n",
    "               shuffle=True,\n",
    "               validation_data = (predictors_test[:1000], label_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
